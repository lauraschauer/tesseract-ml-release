{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tesseract on the DexRay algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 16:58:01.635165: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 16:58:01.711384: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 16:58:01.713630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 16:58:02.861516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random as python_random\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optional import (commented)\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# Local imports\n",
    "from tesseract import evaluation, metrics, mock, temporal, spatial\n",
    "\n",
    "\n",
    "random_seed = 123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "APK_METADATA_PATH = \"/scratch/users/mbenali/metadata.csv\"\n",
    "\n",
    "GOODWARE_PATH = \"/scratch/users/mbenali/download_apk/images/goodware\"\n",
    "MALWARE_PATH = \"/scratch/users/mbenali/download_apk/images/malware\"\n",
    "\n",
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Plots\n",
    "\n",
    "The first plot shows the distribution of all 10000 APKs.\n",
    "\n",
    "Helper function `load_images()` to load and preprocess the grayscale images into a numpy array X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dates_from_csv():\n",
    "    # List to hold the date objects\n",
    "    date_list = []\n",
    "    \n",
    "    # Open and read the CSV file\n",
    "    with open(APK_METADATA_PATH) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            # Convert the string from the 4th column to a datetime object\n",
    "            try:\n",
    "                date = datetime.strptime(row[3], '%Y-%m-%d %H:%M:%S')\n",
    "                date_list.append(date)\n",
    "            except ValueError:\n",
    "                # Handle invalid date format if necessary\n",
    "                pass\n",
    "    \n",
    "    # Convert the list of datetime objects to a numpy array\n",
    "    return np.array(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dates \u001b[38;5;241m=\u001b[39m \u001b[43mextract_dates_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(dates, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mextract_dates_from_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Convert the string from the 4th column to a datetime object\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         date_list\u001b[38;5;241m.\u001b[39mappend(date)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Handle invalid date format if necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tesseract/lib/python3.10/_strptime.py:571\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gmtoff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     tzdelta \u001b[38;5;241m=\u001b[39m datetime_timedelta(seconds\u001b[38;5;241m=\u001b[39mgmtoff, microseconds\u001b[38;5;241m=\u001b[39mgmtoff_fraction)\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tzname:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dates = extract_dates_from_csv()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dates, bins=100, edgecolor='black', color='skyblue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Histogram of Date Entries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Plot the histogram with bins representing one month\u001b[39;00m\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mdates\u001b[49m, bins\u001b[38;5;241m=\u001b[39mbins, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Set x-axis limits to the range from 2018-01-01 to 2019-12-31\u001b[39;00m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim(start_date, end_date)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the start and end date for the x-axis\n",
    "start_date = datetime(2008, 1, 1)\n",
    "end_date = datetime(2025, 12, 31, 23, 59, 59)\n",
    "\n",
    "# Generate the bin edges (start of each month between 2018 and 2019)\n",
    "bins = []\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    bins.append(current_date)\n",
    "    # Move to the start of the next month\n",
    "    next_month = current_date.replace(day=28) + timedelta(days=4)  # Move to next month's first day\n",
    "    current_date = next_month.replace(day=1)\n",
    "\n",
    "# Plot the histogram with bins representing one month\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dates, bins=bins, edgecolor='black', color='skyblue')\n",
    "\n",
    "# Set x-axis limits to the range from 2018-01-01 to 2019-12-31\n",
    "plt.xlim(start_date, end_date)\n",
    "\n",
    "# Label the axes and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Histogram of Date Entries (2018-2019)')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Auto adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load X, y and temp\n",
    "\n",
    "Here starts the new code getting X from the numpy files, y from the folder name and getting the corresponding date by searching the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_apk_metadata(file_path):\n",
    "    \"\"\"Loads the APK metadata from the CSV file into a dictionary for quick lookups.\"\"\"\n",
    "    metadata = {}\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        reader = csv.DictReader(csv_file, fieldnames=[\n",
    "            'sha256', 'sha1', 'md5', 'date_time', 'number1',\n",
    "            'package', 'number2', 'number3', 'dex_date', 'number4', 'source'\n",
    "        ])\n",
    "        csv_file.seek(0)  # Reset file pointer to the beginning\n",
    "        for row in reader:\n",
    "            metadata[row['sha256']] = row['dex_date']\n",
    "    return metadata\n",
    "\n",
    "def get_date_time_from_hash(search_hash, metadata):\n",
    "    \"\"\"\n",
    "    Retrieves the `dex_date` for the given hash using preloaded metadata.\"\"\"\n",
    "    if search_hash in metadata:\n",
    "        try:\n",
    "            return datetime.strptime(metadata[search_hash], '%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing date for {search_hash}: {e}\")\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_apk_metadata(APK_METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24792509"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMPY_FILES_DIR = \"/scratch/users/mbenali/download_apk/npy2\"\n",
    "# Define timeframe of relevant apps \n",
    "YEAR_START = 2010\n",
    "YEAR_END = 2022\n",
    "\n",
    "def assemble_arrays():\n",
    "    \"\"\"Assembles numpy arrays from .npy files along with their labels and dates.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    temp = []\n",
    "\n",
    "    dirs = [NUMPY_FILES_DIR + '/malware', NUMPY_FILES_DIR + '/goodware']\n",
    "    stop = 0\n",
    "\n",
    "    for directory in dirs:\n",
    "        if not os.path.exists(directory):\n",
    "            continue\n",
    "            \n",
    "        for file in os.listdir(directory):\n",
    "            if stop >= 10000:\n",
    "                break\n",
    "            stop += 1\n",
    "\n",
    "            if not file.endswith('.npy'):\n",
    "                continue\n",
    "\n",
    "            # Obtain the date\n",
    "            apk_date = get_date_time_from_hash(file[:-4], metadata)  # remove .npy\n",
    "\n",
    "            # Do not include if outside of date range\n",
    "            if apk_date is None or apk_date.year < YEAR_START or apk_date.year > YEAR_END:\n",
    "                continue\n",
    "\n",
    "            temp.append(apk_date)\n",
    "\n",
    "            filepath = os.path.join(directory, file)\n",
    "            array = np.load(filepath)\n",
    "            X.append(array.flatten())  # Flattening ensures all arrays are rows\n",
    "\n",
    "            # Obtain the label \n",
    "            y.append(0 if 'goodware' in directory else 1)\n",
    "\n",
    "        print(f\"Done with {directory}\")\n",
    "\n",
    "    return np.stack(X), np.array(y), np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with /scratch/users/mbenali/download_apk/npy2/malware\n",
      "Done with /scratch/users/mbenali/download_apk/npy2/goodware\n"
     ]
    }
   ],
   "source": [
    "X, y, temp = assemble_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59415936, 0.        , 0.5476491 , ..., 0.3806373 , 0.23897058,\n",
       "       0.52254903], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (9031, 16384)\n",
      "Contents of X[0]: [0.59415936 0.         0.5476491  ... 0.3806373  0.23897058 0.52254903]\n",
      "\n",
      "# elements in y: 9031\n",
      "# of unique elements in y (0, 1): [0 1]\n",
      "# of malware samples: 1925\n",
      "# of goodware samples: 7106\n",
      "\n",
      "# elements in temp: 9031\n"
     ]
    }
   ],
   "source": [
    "# Get all sorts of sanity checks\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Contents of X[0]: {X[0]}\")\n",
    "\n",
    "print(f\"\\n# elements in y: {len(y)}\")\n",
    "print(f\"# of unique elements in y (0, 1): {np.unique(y)}\")\n",
    "print(f\"# of malware samples: {len(y[y == 1])}\")\n",
    "print(f\"# of goodware samples: {len(y[y == 0])}\")\n",
    "\n",
    "print(f\"\\n# elements in temp: {len(temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DexRay Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = Sequential()\n",
    "model_architecture.add(\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=12,\n",
    "        activation=\"relu\",\n",
    "        input_shape=(IMG_SIZE * IMG_SIZE, 1),\n",
    "    )\n",
    ")\n",
    "model_architecture.add(MaxPooling1D(pool_size=12))\n",
    "model_architecture.add(Conv1D(filters=128, kernel_size=12, activation=\"relu\"))\n",
    "model_architecture.add(MaxPooling1D(pool_size=12))\n",
    "model_architecture.add(Flatten())\n",
    "model_architecture.add(Dense(64, activation=\"sigmoid\"))\n",
    "model_architecture.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model = keras.models.clone_model(model_architecture)\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom fit function so that we can change the number of epochs.\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=50, restore_best_weights=True\n",
    ")\n",
    "\n",
    "def fit_with_epochs(X_train, y_train):\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        shuffle=True,\n",
    "        epochs=20, # TODO: hardcoded for now because just wanna try\n",
    "        callbacks=[es_callback],\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract\n",
    "\n",
    "Split the data with Tesseract's `time_aware_train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6103, 16384)\n",
      "X_test: 21\n"
     ]
    }
   ],
   "source": [
    "splits = temporal.time_aware_train_test_split(\n",
    "    X, y, temp, train_size=96, test_size=2, granularity='month'\n",
    ")\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = splits\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\") # Sanity Check\n",
    "print(f\"X_test: {len(X_test)}\") # Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample so that there's the requested percentage of malware in the training data\n",
    "downsample = False\n",
    "if downsample:    \n",
    "    train_idxs = spatial.downsample_to_rate(y_train, 0.70)\n",
    "\n",
    "    X_train = X_train[train_idxs]\n",
    "    y_train = y_train[train_idxs]\n",
    "    temp_train = t_train[train_idxs]\n",
    "\n",
    "    print(f\"# of malware samples: {len(y_train[y_train == 1])}\")\n",
    "    print(f\"# of goodware samples: {len(y_train[y_train == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 26s - loss: 0.3245 - 26s/epoch - 137ms/step\n",
      "Epoch 2/20\n",
      "191/191 - 26s - loss: 0.2854 - 26s/epoch - 134ms/step\n",
      "Epoch 3/20\n",
      "191/191 - 26s - loss: 0.2337 - 26s/epoch - 134ms/step\n",
      "Epoch 4/20\n",
      "191/191 - 26s - loss: 0.1841 - 26s/epoch - 134ms/step\n",
      "Epoch 5/20\n",
      "191/191 - 26s - loss: 0.1247 - 26s/epoch - 134ms/step\n",
      "Epoch 6/20\n",
      "191/191 - 26s - loss: 0.0833 - 26s/epoch - 134ms/step\n",
      "Epoch 7/20\n"
     ]
    }
   ],
   "source": [
    "results = evaluation.fit_predict_update(model, *splits, fit_function=fit_with_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------+---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Test period |     1      2      3      4      5      6      7      8      9     10     11     12     13     14     15     16     17     18     19     20     21   \n",
      "------------+---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Actual pos  |     38     74     16     36     62     21     18     14     13     13     26     23     15     38    103     75     15      9     54     43      6\n",
      "Actual neg  |    115    133     33     46     98    245     96     55     60     41     46     63     61    220    406    141     95     42     43    161     16\n",
      "Total       |    153    207     49     82    160    266    114     69     73     54     72     86     76    258    509    216    110     51     97    204     22\n",
      "------------+---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "TPR         |  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "FPR         |  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "TNR         |  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "FNR         |  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "AUC ROC     |  0.675  0.696  0.830  0.699  0.633  0.675  0.666  0.478  0.676  0.568  0.612  0.514  0.584  0.714  0.817  0.823  0.782  0.802  0.655  0.748  0.854\n",
      "------------+---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Precision   |  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "Recall      |  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "F1          |  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "------------+---------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics.print_metrics(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesseract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
